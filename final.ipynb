{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chlwnsxo00/BigDataSecurity/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 드라이브 설정"
      ],
      "metadata": {
        "id": "Aale8Jxv8bhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM_o_ZM66OcU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/Shareddrives/BigDataSecurity'"
      ],
      "metadata": {
        "id": "YsYarYqG6S4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "HzfOCDO86Wxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모듈 불러오기"
      ],
      "metadata": {
        "id": "LlbI6roy8goa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "import torch.utils.data\n",
        "import os\n",
        "import time\n",
        "# 전처리\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ckUwJYuE6Zep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "from PIL import Image\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True # prevent truncate error"
      ],
      "metadata": {
        "id": "3LEOq0sGlUdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 불러오기\n"
      ],
      "metadata": {
        "id": "UMfcc6IX8l-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root, malware_list, transform=None):\n",
        "        self.root = root\n",
        "        self.malware_list = malware_list\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "        self.folder_to_label = {}  # 폴더명과 클래스 레이블 매핑을 위한 딕셔너리\n",
        "        self.malware_type = []\n",
        "\n",
        "        for idx, folder_name in enumerate(os.listdir(root)):\n",
        "            if folder_name in malware_list:\n",
        "                folder_path = os.path.join(root, folder_name)\n",
        "                self.folder_to_label[folder_name] = self.label_transform(folder_name)  # 폴더명에 대한 레이블 변환 결과 저장\n",
        "\n",
        "                for image_name in os.listdir(folder_path):\n",
        "                    if image_name.endswith('.png'):  # 이미지 파일 확장자 지정\n",
        "                        image_path = os.path.join(folder_path, image_name)\n",
        "                        self.malware_type.append(folder_name)\n",
        "                        self.data.append(image_path)\n",
        "                        self.targets.append(folder_name)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.data[index]\n",
        "        target = self.targets[index]\n",
        "        image = Image.open(image_path)\n",
        "        malware_type = self.malware_type[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        target = self.folder_to_label[target]  # 폴더명에 대한 레이블 변환 결과 가져오기\n",
        "        return image, target, image_path, malware_type\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def label_transform(self, label):\n",
        "        # 예시: 폴더명을 기준으로 클래스 레이블 변환\n",
        "        if label != 'Other':\n",
        "            return 0\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "def concat_datasets(datasets):\n",
        "    return ConcatDataset(datasets)\n"
      ],
      "metadata": {
        "id": "nMHaAty5DaVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지의 RGB 채널별 통계량 확인 함수\n",
        "def print_stats(dataset):\n",
        "    imgs = np.array([img.numpy() for img, _, _ in dataset])\n",
        "    print(f'shape: {imgs.shape}')\n",
        "\n",
        "    min_r = np.min(imgs, axis=(2, 3))[:, 0].min()\n",
        "    min_g = np.min(imgs, axis=(2, 3))[:, 1].min()\n",
        "    min_b = np.min(imgs, axis=(2, 3))[:, 2].min()\n",
        "\n",
        "    max_r = np.max(imgs, axis=(2, 3))[:, 0].max()\n",
        "    max_g = np.max(imgs, axis=(2, 3))[:, 1].max()\n",
        "    max_b = np.max(imgs, axis=(2, 3))[:, 2].max()\n",
        "\n",
        "    mean_r = np.mean(imgs, axis=(2, 3))[:, 0].mean()\n",
        "    mean_g = np.mean(imgs, axis=(2, 3))[:, 1].mean()\n",
        "    mean_b = np.mean(imgs, axis=(2, 3))[:, 2].mean()\n",
        "\n",
        "    std_r = np.std(imgs, axis=(2, 3))[:, 0].std()\n",
        "    std_g = np.std(imgs, axis=(2, 3))[:, 1].std()\n",
        "    std_b = np.std(imgs, axis=(2, 3))[:, 2].std()\n",
        "\n",
        "    print(f'min: {min_r, min_g, min_b}')\n",
        "    print(f'max: {max_r, max_g, max_b}')\n",
        "    print(f'mean: {mean_r, mean_g, mean_b}')\n",
        "    print(f'std: {std_r, std_g, std_b}')"
      ],
      "metadata": {
        "id": "2DL1Sw4bq4eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "T5vzERbMq--u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_transforms1 = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "}\n",
        "\n",
        "image_transforms2 = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "yE3cKQrFlhK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "malware_list = {'Adposhel': 0,\n",
        " 'Allaple': 0,\n",
        " 'Amonetize': 0,\n",
        " 'Autorun': 0,\n",
        " 'Other': 1,\n",
        " 'BrowseFox': 0,\n",
        " 'Dinwod': 0,\n",
        " 'InstallCore': 0,\n",
        " 'MultiPlug': 0,\n",
        " 'VBA': 0,\n",
        " 'Vilsel': 0}"
      ],
      "metadata": {
        "id": "wlneD9fy4ivH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_transform(label):\n",
        "    # 예시: 클래스 레이블을 원하는 형태로 변환\n",
        "    if label != 4:\n",
        "      return 0\n",
        "    else:\n",
        "      return 1"
      ],
      "metadata": {
        "id": "Lax6SL6-4l11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path1 = './malware/train'\n",
        "test_path1 = './malware/val'\n",
        "train_path2 = './malware2/train'\n",
        "test_path2 = './malware2/val'"
      ],
      "metadata": {
        "id": "zJGDdX9NDeTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data1 = CustomDataset(root = train_path1, malware_list=malware_list,\n",
        "                                  transform = image_transforms['train'])\n",
        "train_data2 = CustomDataset(root = train_path2, malware_list=malware_list,\n",
        "                                  transform = image_transforms['train'])"
      ],
      "metadata": {
        "id": "y40ZwosJlzy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data1 = CustomDataset(root = test_path1, malware_list=malware_list,\n",
        "                                  transform = image_transforms['test'])\n",
        "test_data2 = CustomDataset(root = test_path2, malware_list=malware_list,\n",
        "                                  transform = image_transforms['test'])"
      ],
      "metadata": {
        "id": "SfHDr1YE8r4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total : 13,566\n",
        "# Train : 10852\n",
        "# Test : 2714(1357 * 2)"
      ],
      "metadata": {
        "id": "uE6FNq_pxa9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data1))\n",
        "print(len(train_data2))\n",
        "print(len(test_data1))\n",
        "print(len(test_data2))"
      ],
      "metadata": {
        "id": "r4RD3L18e5fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset rebalance\n",
        "test_data, add_data = torch.utils.data.random_split(test_data2, [2714, 220])\n",
        "\n",
        "train_data = ConcatDataset([train_data1, train_data2, test_data1, add_data])"
      ],
      "metadata": {
        "id": "IbvHCg1jk2u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TestLoader(Dataset):\n",
        "  val_size = int(0.5 * len(Dataset))\n",
        "  test_size = int(0.5 * len(Dataset))\n",
        "\n",
        "  valid_data, test_data = torch.utils.data.random_split(Dataset, [val_size, test_size])\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=128, shuffle=False) # make test loader\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False) # make test loader\n",
        "\n",
        "  return valid_loader, test_loader"
      ],
      "metadata": {
        "id": "L18Aa_1PDnIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True) # make train loader\n",
        "valid_loader, test_loader = TestLoader(test_data) # make valid & test loader"
      ],
      "metadata": {
        "id": "jW1vepJ_mGQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_datasize():\n",
        "  print(f'Number of training examples: {len(train_data)}')\n",
        "  print(f'Number of validation examples: {int(len(test_data) / 2)}')\n",
        "  print(f'Number of testing examples: {int(len(test_data) / 2)}')\n",
        "\n",
        "show_datasize()"
      ],
      "metadata": {
        "id": "cS7alUIxwkKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_to_idx  = malware_list # class name"
      ],
      "metadata": {
        "id": "mRfacWXn5Jbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = train_data.class_to_idx\n",
        "classes"
      ],
      "metadata": {
        "id": "_H9c_LG_6WKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # functions to show an image\n",
        "\n",
        "\n",
        "# def imshow(img):\n",
        "#     npimg = img.numpy()\n",
        "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "# # get some random training images\n",
        "# dataiter = iter(train_loader)\n",
        "# # print(dataiter.next())\n",
        "# images, labels = next(dataiter)\n",
        "\n",
        "# batch_size = 16\n",
        "\n",
        "# # show images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# # print labels\n",
        "# print()\n",
        "\n",
        "# labels = labels.tolist()\n",
        "# print(' '.join(f'{list(classes.keys())[list(classes.values()).index(j)]}' for j in labels))"
      ],
      "metadata": {
        "id": "A5r9_7v1mCHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리"
      ],
      "metadata": {
        "id": "9kIZ0uDE8sfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Laplacian Filtering (Edge 강화) && Bilateral Filtering (노이즈 제거) 적용"
      ],
      "metadata": {
        "id": "b-MA38uyZAg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# # Train 폴더 위치\n",
        "# train_folder = './malware/train/'\n",
        "\n",
        "# # Bila_Train 폴더 위치\n",
        "# bila_folder = '/home/Bila_folder1'\n",
        "\n",
        "# # Laplace_Bila_Train 폴더 위치\n",
        "# both_folder = '/home/both_folder1'\n",
        "\n",
        "# # 모든 클래스에 대해 불러옵니다.\n",
        "# for class_folder in os.walk(train_folder).__next__()[1]:\n",
        "#     # 클래스 이름을 불러옵니다.\n",
        "#     class_name = class_folder\n",
        "#     # 클래스 폴더의 경로를 붙여넣습니다.\n",
        "#     class_folder_path = os.path.join(train_folder, class_folder)\n",
        "#     # Bila_Train 폴더에 저장할 경로를 지정하고 생성합니다.\n",
        "#     bila_class_folder_path = os.path.join(bila_folder, class_folder)\n",
        "#     # Both_Train 폴더에 저장할 경로를 지정하고 생성합니다.\n",
        "#     both_class_folder_path = os.path.join(both_folder, class_folder)\n",
        "#     os.makedirs(both_class_folder_path, exist_ok=True)\n",
        "\n",
        "#     # 클래스 폴더를 순회하며 Laplacian Filtering과 Bilateral Filtering을 적용한 이미지를 저장합니다.\n",
        "#     for image_file in os.listdir(class_folder_path):\n",
        "#         # 파일 경로를 붙여넣습니다.\n",
        "#         image_file_path = os.path.join(class_folder_path, image_file)\n",
        "\n",
        "#         # 이미지 파일을 불러옵니다.\n",
        "#         image = cv2.imread(image_file_path)\n",
        "\n",
        "#         # 이미지가 제대로 불러와지지 않은 경우 다음 이미지로 넘어갑니다.\n",
        "#         if image is None:\n",
        "#             continue\n",
        "\n",
        "#         # Laplacian Filtering을 적용합니다.\n",
        "#         lap_image = cv2.Laplacian(image, cv2.CV_8U, ksize=3)\n",
        "\n",
        "#         # Bilateral Filtering을 적용합니다.\n",
        "#         bila_image = cv2.bilateralFilter(image, -1, 10, 5)\n",
        "\n",
        "#         # Laplace_Bila_Train 폴더에 라플라시안 이미지를 저장합니다.\n",
        "#         lap_image_path = os.path.join(both_class_folder_path, 'lap_' + image_file)\n",
        "#         cv2.imwrite(lap_image_path, lap_image)\n",
        "\n",
        "#         # Laplace_Bila_Train 폴더에 Bilateral 이미지를 저장합니다.\n",
        "#         bila_image_path = os.path.join(both_class_folder_path, 'bila_' + image_file)\n",
        "#         cv2.imwrite(bila_image_path, bila_image)\n",
        "\n",
        "#         # 파일 경로를 붙여넣습니다.\n",
        "#         both_image_path = os.path.join(both_class_folder_path, 'both_' + image_file)\n",
        "\n",
        "#         # both 이미지가 이미 저장된 경우 lap_image와 bila_image의 기존 이미지를 제거하고 both_image를 저장합니다.\n",
        "#         if os.path.isfile(both_image_path):\n",
        "#             os.remove(lap_image_path)\n",
        "#             os.remove(bila_image_path)\n",
        "\n",
        "#         # 이미지를 불러와서 Laplacian Filtering과 Bilateral Filtering을 모두 적용합니다.\n",
        "#         lap_image = cv2.imread(lap_image_path)\n",
        "#         bila_image = cv2.imread(bila_image_path)\n",
        "\n",
        "#         # 이미지가 제대로 불러와지지 않은 경우 다음 이미지로 넘어갑니다.\n",
        "#         if lap_image is None or bila_image is None:\n",
        "#             continue\n",
        "\n",
        "#         both_image = cv2.addWeighted(lap_image, 0.5, bila_image, 0.5, 0)\n",
        "\n",
        "#         # Laplace_Bila_Train 폴더에 Laplacian Filtering과 Bilateral Filtering을 모두 적용한 이미지를 저장합니다.\n",
        "#         cv2.imwrite(both_image_path, both_image)"
      ],
      "metadata": {
        "id": "0y1-WZ0kZBRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# # Train 폴더 위치\n",
        "# train_folder = './malware2/train/'\n",
        "\n",
        "# # Bila_Train 폴더 위치\n",
        "# bila_folder = '/home/Bila_folder2'\n",
        "\n",
        "# # Laplace_Bila_Train 폴더 위치\n",
        "# both_folder = '/home/both_folder2'\n",
        "\n",
        "# # 모든 클래스에 대해 불러옵니다.\n",
        "# for class_folder in os.walk(train_folder).__next__()[1]:\n",
        "#     # 클래스 이름을 불러옵니다.\n",
        "#     class_name = class_folder\n",
        "#     # 클래스 폴더의 경로를 붙여넣습니다.\n",
        "#     class_folder_path = os.path.join(train_folder, class_folder)\n",
        "#     # Bila_Train 폴더에 저장할 경로를 지정하고 생성합니다.\n",
        "#     bila_class_folder_path = os.path.join(bila_folder, class_folder)\n",
        "#     # Both_Train 폴더에 저장할 경로를 지정하고 생성합니다.\n",
        "#     both_class_folder_path = os.path.join(both_folder, class_folder)\n",
        "#     os.makedirs(both_class_folder_path, exist_ok=True)\n",
        "\n",
        "#     # 클래스 폴더를 순회하며 Laplacian Filtering과 Bilateral Filtering을 적용한 이미지를 저장합니다.\n",
        "#     for image_file in os.listdir(class_folder_path):\n",
        "#         # 파일 경로를 붙여넣습니다.\n",
        "#         image_file_path = os.path.join(class_folder_path, image_file)\n",
        "\n",
        "#         # 이미지 파일을 불러옵니다.\n",
        "#         image = cv2.imread(image_file_path)\n",
        "\n",
        "#         # 이미지가 제대로 불러와지지 않은 경우 다음 이미지로 넘어갑니다.\n",
        "#         if image is None:\n",
        "#             continue\n",
        "\n",
        "#         # Laplacian Filtering을 적용합니다.\n",
        "#         lap_image = cv2.Laplacian(image, cv2.CV_8U, ksize=3)\n",
        "\n",
        "#         # Bilateral Filtering을 적용합니다.\n",
        "#         bila_image = cv2.bilateralFilter(image, -1, 10, 5)\n",
        "\n",
        "#         # Laplace_Bila_Train 폴더에 라플라시안 이미지를 저장합니다.\n",
        "#         lap_image_path = os.path.join(both_class_folder_path, 'lap_' + image_file)\n",
        "#         cv2.imwrite(lap_image_path, lap_image)\n",
        "\n",
        "#         # Laplace_Bila_Train 폴더에 Bilateral 이미지를 저장합니다.\n",
        "#         bila_image_path = os.path.join(both_class_folder_path, 'bila_' + image_file)\n",
        "#         cv2.imwrite(bila_image_path, bila_image)\n",
        "\n",
        "#         # 파일 경로를 붙여넣습니다.\n",
        "#         both_image_path = os.path.join(both_class_folder_path, 'both_' + image_file)\n",
        "\n",
        "#         # both 이미지가 이미 저장된 경우 lap_image와 bila_image의 기존 이미지를 제거하고 both_image를 저장합니다.\n",
        "#         if os.path.isfile(both_image_path):\n",
        "#             os.remove(lap_image_path)\n",
        "#             os.remove(bila_image_path)\n",
        "\n",
        "#         # 이미지를 불러와서 Laplacian Filtering과 Bilateral Filtering을 모두 적용합니다.\n",
        "#         lap_image = cv2.imread(lap_image_path)\n",
        "#         bila_image = cv2.imread(bila_image_path)\n",
        "\n",
        "#         # 이미지가 제대로 불러와지지 않은 경우 다음 이미지로 넘어갑니다.\n",
        "#         if lap_image is None or bila_image is None:\n",
        "#             continue\n",
        "\n",
        "#         both_image = cv2.addWeighted(lap_image, 0.5, bila_image, 0.5, 0)\n",
        "\n",
        "#         # Laplace_Bila_Train 폴더에 Laplacian Filtering과 Bilateral Filtering을 모두 적용한 이미지를 저장합니다.\n",
        "#         cv2.imwrite(both_image_path, both_image)"
      ],
      "metadata": {
        "id": "CqpYanGji1eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HOG"
      ],
      "metadata": {
        "id": "FWmDitISpg_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-image"
      ],
      "metadata": {
        "id": "tWeu-VIFZF9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.util import view_as_blocks\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "mvNsGu4zZGhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gabor 필터 생성 함수\n",
        "def create_filters(scales, orientations):\n",
        "    filters = []\n",
        "    for scale in range(scales[0], scales[1] + 1):\n",
        "        for orientation in np.arange(0, np.pi, np.pi / orientations):\n",
        "            filt_real = cv2.getGaborKernel((scale, scale), 1, orientation, scale, 0, ktype=cv2.CV_32F)\n",
        "            filt_imag = cv2.getGaborKernel((scale, scale), 1, orientation, scale, 0.5 * np.pi, ktype=cv2.CV_32F)\n",
        "            filt = filt_real + filt_imag\n",
        "            filt /= 2.0 * np.pi * scale * scale\n",
        "            filters.append(filt)\n",
        "    return filters\n",
        "\n",
        "# HOG 디스크립터 계산 함수\n",
        "def hog_descriptor_single_channel(image, scales=(8, 8), orientations=8, blocks=(4, 4)):    # Gabor 필터 생성\n",
        "    filters = create_filters(scales, orientations)\n",
        "\n",
        "    # 이미지 크기와 블록 크기 계산\n",
        "    height, width = image.shape[:2]\n",
        "    block_size = height // blocks[0], width // blocks[1]\n",
        "\n",
        "    padding_size = blocks[0] * block_size[0] - height, blocks[1] * block_size[1] - width\n",
        "\n",
        "    # 이미지 패딩 (필요한 경우)\n",
        "    if padding_size != (0, 0):\n",
        "        image = cv2.copyMakeBorder(image, 0, padding_size[0], 0, padding_size[1], cv2.BORDER_CONSTANT, value=0)\n",
        "\n",
        "    # 이미지를 블록으로 분할\n",
        "    block_shape = (block_size[0], block_size[1])\n",
        "    blocks = view_as_blocks(image, block_shape=(block_size[0], block_size[1])).reshape(-1, *block_size, order='F')\n",
        "\n",
        "    # 각 블록의 hog 특성 추출\n",
        "    features = []\n",
        "    for block in blocks:\n",
        "        feats = []\n",
        "        for scale in filters:\n",
        "            for filt in scale:\n",
        "                filtered = cv2.filter2D(block, cv2.CV_64F, filt)\n",
        "                feats.append(filtered.mean())\n",
        "        features.append(feats)\n",
        "\n",
        "    # 전체 hog 디스크립터로 결합\n",
        "    return np.concatenate(features)\n",
        "\n",
        "\n",
        "def hog_descriptor(image, scales=(8, 8), orientations=8, blocks=(4, 4)):\n",
        "    if len(image.shape) == 3:\n",
        "    # 각 채널에 대해 hog 디스크립터 계산\n",
        "        descriptors = [hog_descriptor_single_channel(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), scales, orientations, blocks)]            # 전체 GIST 디스크립터로 결합\n",
        "        return np.concatenate(descriptors)\n",
        "    else:\n",
        "    # 단일 채널 이미지의 경우 hog 디스크립터를 한 번만 계산\n",
        "        return hog_descriptor_single_channel(image, scales, orientations, blocks)\n",
        "\n",
        "# 각 이미지에 맞는 레이블 생성\n",
        "def load_labels(dir, num_samples):\n",
        "    y = []\n",
        "    for subdir in sorted(os.listdir(dir)):\n",
        "        subdir_path = os.path.join(dir, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            for i, filename in enumerate(sorted(os.listdir(subdir_path))):\n",
        "                y.append(labels_dict[subdir])\n",
        "                if len(y) == num_samples:\n",
        "                    break\n",
        "        if len(y) == num_samples:\n",
        "            break\n",
        "    return np.array(y)"
      ],
      "metadata": {
        "id": "mUpKHcYAZHua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 악성코드 이미지 폴더에서 350개의 이미지에 대한 hog descriptor를 계산하여 반환\n",
        "def get_hog_descriptors(train_data):\n",
        "    descriptors = []\n",
        "    labels = []\n",
        "    for i, v in enumerate(train_data):\n",
        "      _,label,path = v\n",
        "      # 파일 경로 생성\n",
        "      # 이미지 로드\n",
        "      image = cv2.imread(path)\n",
        "      # 이미지에 대한 hog 디스크립터 계산\n",
        "      descriptor = hog_descriptor(image)\n",
        "      descriptors.append(descriptor)\n",
        "      labels.append(label)\n",
        "      if i % 100 == 99:\n",
        "        print(\"\\tProcessed\", i + 1, \"images\")\n",
        "    return np.array(descriptors) , np.array(labels)"
      ],
      "metadata": {
        "id": "OMbZDXGqZJGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descriptors, train_labels = get_hog_descriptors(train_data)\n",
        "print(len(descriptors))\n",
        "print('HOG Descriptor Shape:', descriptors.shape)"
      ],
      "metadata": {
        "id": "-Ay2mEfnvQAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터와 레이블 설정\n",
        "X = descriptors\n",
        "hog_features = X\n",
        "\n",
        "# hog_descriptors 및 레이블 불러오기\n",
        "X_train = X\n",
        "X_val , val_label= get_hog_descriptors(add_data)\n",
        "X_test, test_label = get_hog_descriptors(test_data)"
      ],
      "metadata": {
        "id": "7tExoHv8ZKr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix"
      ],
      "metadata": {
        "id": "VM3RYA1FZL-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_transforms1 = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.37306938, 0.3730843, 0.3727943), (0.07064196, 0.0706386, 0.07048721))\n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomRotation((-20, 20)),\n",
        "        transforms.RandomGrayscale(p=0.8),\n",
        "        transforms.RandomHorizontalFlip(p=0.8),\n",
        "        transforms.RandomVerticalFlip(p=0.8),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.37306938, 0.3730843, 0.3727943), (0.07064196, 0.0706386, 0.07048721))\n",
        "    ])\n",
        "}\n",
        "\n",
        "image_transforms2 = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomRotation((-20, 20)),\n",
        "        transforms.RandomGrayscale(p=0.8),\n",
        "        transforms.RandomHorizontalFlip(p=0.8),\n",
        "        transforms.RandomVerticalFlip(p=0.8),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.37306938, 0.3730843, 0.3727943), (0.07064196, 0.0706386, 0.07048721))\n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.37306938, 0.3730843, 0.3727943), (0.07064196, 0.0706386, 0.07048721))\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "FnIBEtexZNTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data1 = CustomDataset(root = train_path1, malware_list=malware_list,\n",
        "                                  transform = image_transforms1['train'])\n",
        "train_data2 = CustomDataset(root = train_path2, malware_list=malware_list,\n",
        "                                  transform = image_transforms2['train'])\n",
        "\n",
        "test_data1 = CustomDataset(root = test_path1, malware_list=malware_list,\n",
        "                                  transform = image_transforms1['test'])\n",
        "test_data2 = CustomDataset(root = test_path2, malware_list=malware_list,\n",
        "                                  transform = image_transforms2['test'])"
      ],
      "metadata": {
        "id": "umUJ5scEZOf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GIST"
      ],
      "metadata": {
        "id": "E_Dqm17NFFTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.util import view_as_blocks"
      ],
      "metadata": {
        "id": "g9fAU5z4qpff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gabor 필터 생성 함수\n",
        "def create_filters(scales, orientations):\n",
        "    filters = []\n",
        "    for scale in range(scales[0], scales[1] + 1):\n",
        "        for orientation in np.arange(0, np.pi, np.pi / orientations):\n",
        "            filt_real = cv2.getGaborKernel((scale, scale), 1, orientation, scale, 0, ktype=cv2.CV_32F)\n",
        "            filt_imag = cv2.getGaborKernel((scale, scale), 1, orientation, scale, 0.5 * np.pi, ktype=cv2.CV_32F)\n",
        "            filt = filt_real + filt_imag\n",
        "            filt /= 2.0 * np.pi * scale * scale\n",
        "            filters.append(filt)\n",
        "    return filters\n",
        "\n",
        "# GIST 디스크립터 계산 함수\n",
        "def gist_descriptor_single_channel(image, scales=(8, 8), orientations=8, blocks=(4, 4)):    # Gabor 필터 생성\n",
        "    filters = create_filters(scales, orientations)\n",
        "\n",
        "    # 이미지 크기와 블록 크기 계산\n",
        "    height, width = image.shape[:2]\n",
        "    block_size = height // blocks[0], width // blocks[1]\n",
        "\n",
        "    padding_size = blocks[0] * block_size[0] - height, blocks[1] * block_size[1] - width\n",
        "\n",
        "    # 이미지 패딩 (필요한 경우)\n",
        "    if padding_size != (0, 0):\n",
        "        image = cv2.copyMakeBorder(image, 0, padding_size[0], 0, padding_size[1], cv2.BORDER_CONSTANT, value=0)\n",
        "\n",
        "    # 이미지를 블록으로 분할\n",
        "    block_shape = (block_size[0], block_size[1])\n",
        "    blocks = view_as_blocks(image, block_shape=(block_size[0], block_size[1])).reshape(-1, *block_size, order='F')\n",
        "\n",
        "    # 각 블록의 GIST 특성 추출\n",
        "    features = []\n",
        "    for block in blocks:\n",
        "        feats = []\n",
        "        for scale in filters:\n",
        "            for filt in scale:\n",
        "                filtered = cv2.filter2D(block, cv2.CV_64F, filt)\n",
        "                feats.append(filtered.mean())\n",
        "        features.append(feats)\n",
        "\n",
        "    # 전체 GIST 디스크립터로 결합\n",
        "    return np.concatenate(features)\n",
        "\n",
        "\n",
        "def gist_descriptor(image, scales=(8, 8), orientations=8, blocks=(4, 4)):\n",
        "    if len(image.shape) == 3:\n",
        "    # 각 채널에 대해 GIST 디스크립터 계산\n",
        "        descriptors = [gist_descriptor_single_channel(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), scales, orientations, blocks)]            # 전체 GIST 디스크립터로 결합\n",
        "        return np.concatenate(descriptors)\n",
        "    else:\n",
        "    # 단일 채널 이미지의 경우 GIST 디스크립터를 한 번만 계산\n",
        "        return gist_descriptor_single_channel(image, scales, orientations, blocks)\n"
      ],
      "metadata": {
        "id": "qr4x57TSr8tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 악성코드 이미지 폴더에서 350개의 이미지에 대한 gist descriptor를 계산하여 반환\n",
        "def get_gist_descriptors(root_dir):\n",
        "    descriptors = []\n",
        "    for subdir in sorted(os.listdir(root_dir)):\n",
        "        subdir_path = os.path.join(root_dir, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            print(\"Processing directory:\", subdir_path)\n",
        "            for i, filename in enumerate(os.listdir(subdir_path)):\n",
        "                # 파일 경로 생성\n",
        "                filepath = os.path.join(subdir_path, filename)\n",
        "                # 이미지 로드\n",
        "                image = cv2.imread(filepath)\n",
        "                # 이미지에 대한 GIST 디스크립터 계산\n",
        "                descriptor = gist_descriptor(image)\n",
        "                descriptors.append(descriptor)\n",
        "\n",
        "                if i % 10 == 9:\n",
        "                    print(\"\\tProcessed\", i + 1, \"images\")\n",
        "    return np.array(descriptors)"
      ],
      "metadata": {
        "id": "K6l1xtUD8ysZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_image(image, width, height):\n",
        "    return cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "def get_GIST_descriptors(train_data, img_width=64, img_height=64):\n",
        "    gist_descriptors = []\n",
        "    train_labels = []\n",
        "\n",
        "    for i, v in enumerate(train_data):\n",
        "        _, label, path = v\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # 이미지 크기 조정\n",
        "        img = resize_image(img, img_width, img_height)\n",
        "\n",
        "        gist_descriptor = gist(img, orientations=8, pixels_per_cell=(8, 8),\n",
        "                             cells_per_block=(1, 1), block_norm='L2-Hys')\n",
        "        gist_descriptors.append(gist_descriptor)\n",
        "        train_labels.append(label)\n",
        "\n",
        "        # 진행 상황 출력\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Processed {i + 1} images\")\n",
        "\n",
        "    gist_descriptors = np.array(gist_descriptors)\n",
        "    return gist_descriptors, train_labels\n",
        "\n",
        "# Assuming 'train_data' is a list of (_, label, path) tuples\n",
        "h_descriptors, train_labels = get_GIST_descriptors(train_data)"
      ],
      "metadata": {
        "id": "9SI1S6TDY9TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터와 레이블 설정\n",
        "X = h_descriptors\n",
        "gist_features = X\n",
        "\n",
        "# gist_descriptors 및 레이블 불러오기\n",
        "X_train = X\n",
        "X_val , val_label= get_GIST_descriptors(add_data)\n",
        "X_test, test_label = get_GIST_descriptors(test_data)"
      ],
      "metadata": {
        "id": "6N9yeZsxb3kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SIFT"
      ],
      "metadata": {
        "id": "LPbFf12KjLrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sift_features = []\n",
        "sift = cv2.xfeatures2d.SIFT_create()"
      ],
      "metadata": {
        "id": "XAQZhRN-CD-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def get_sift_descriptors(train_data):\n",
        "    sift = cv2.SIFT_create()\n",
        "    sift_descriptors = []\n",
        "    train_labels = []\n",
        "\n",
        "    for i, v in enumerate(train_data):\n",
        "        _, label, path = v\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        _, descriptor = sift.detectAndCompute(img, None)\n",
        "\n",
        "        # If no feature is detected, skip this image\n",
        "        if descriptor is None:\n",
        "            continue\n",
        "\n",
        "        sift_descriptors.append(descriptor)\n",
        "        train_labels.append(label)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Processed {i + 1} images\")\n",
        "\n",
        "    # Convert the list of descriptors to an ndarray\n",
        "    # and zero-padding to match image with fewer keypoints\n",
        "    max_keypoints = max([desc.shape[0] for desc in sift_descriptors])\n",
        "    s_descriptors = np.zeros((len(sift_descriptors), max_keypoints, 128))\n",
        "    for i, desc in enumerate(sift_descriptors):\n",
        "        s_descriptors[i, :desc.shape[0], :] = desc\n",
        "\n",
        "    return s_descriptors, train_labels\n",
        "\n",
        "# Assuming 'train_data' is a list of (_, label, path) tuples\n",
        "s_descriptors, train_labels = get_sift_descriptors(train_data)\n",
        "print(len(s_descriptors))\n",
        "print('SIFT Descriptor Shape:', s_descriptors.shape)"
      ],
      "metadata": {
        "id": "T9cnUIx2ByJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터와 레이블 설정\n",
        "X = s_descriptors\n",
        "\n",
        "# hog_descriptors 및 레이블 불러오기\n",
        "X_train = X\n",
        "X_val , val_label= get_sift_descriptors(add_data)\n",
        "X_test, test_label = get_sift_descriptors(test_data)"
      ],
      "metadata": {
        "id": "rH3EIB-oBsAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming s_descriptors is the 3D SIFT descriptors array with shape (num_samples, num_keypoints, num_features)\n",
        "\n",
        "# Step 1: Flatten SIFT descriptors from 3D to 2D\n",
        "s_descriptors_flat = s_descriptors.reshape(s_descriptors.shape[0], -1)\n",
        "\n",
        "# Step 2: Apply StandardScaler to the flattened 2D array\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(s_descriptors_flat)\n",
        "\n",
        "# Now, train the model with the transformed data\n",
        "model_instance.fit(X_train, train_labels)\n"
      ],
      "metadata": {
        "id": "vOceLSv1ZXz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EDA"
      ],
      "metadata": {
        "id": "Nm3SIBpBqxeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train_data에 대한 클래스별 데이터 분포(pie graph)"
      ],
      "metadata": {
        "id": "aJ_zUt3bZje3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the number of samples for each class in train_data\n",
        "class_counts = [0] * len(malware_list)\n",
        "\n",
        "for idx in range(len(train_data)):\n",
        "  image, label, path, malware_type = train_data[idx]\n",
        "  for i, mt in enumerate(classes):\n",
        "    if mt == malware_type:\n",
        "      class_counts[i] += 1\n",
        "\n",
        "class_names = list(malware_list.keys())\n",
        "\n",
        "for i, mt in enumerate(classes):\n",
        "  print(mt + \" : \" + str(class_counts[i]))\n",
        "\n",
        "# Plot the pie chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(class_counts, labels=class_names, autopct='%1.1f%%')\n",
        "plt.title('Train Data Class Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pl7dmznmZmZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###test_data에 대한 클래스별 데이터 분포(pie graph)"
      ],
      "metadata": {
        "id": "BE18IgysZpih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the number of samples for each class in test_data\n",
        "class_counts = [0] * len(malware_list)\n",
        "\n",
        "for idx in range(len(test_data)):\n",
        "  image, label, path, malware_type = test_data[idx]\n",
        "  for i, mt in enumerate(classes):\n",
        "    if mt == malware_type:\n",
        "      class_counts[i] += 1\n",
        "\n",
        "class_names = list(malware_list.keys())"
      ],
      "metadata": {
        "id": "fD8yeRWMZrCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, mt in enumerate(classes):\n",
        "  print(mt + \" : \" + str(class_counts[i]))\n",
        "\n",
        "# Plot the pie chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(class_counts, labels=class_names, autopct='%1.1f%%')\n",
        "plt.title('Test Data Class Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3zQti13XnSrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 불러오기"
      ],
      "metadata": {
        "id": "gD8-uypZr5RU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE # sklearn 사용하면 easy !!\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "UvC0K5rwkMGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시각화에 사용할 모델 불러오기"
      ],
      "metadata": {
        "id": "N0PkaiN0kT07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "model = torchvision.models.resnet18(pretrained=False)\n",
        "num_ftrs = model.fc.in_features # fc의 입력 노드 수를 산출한다. 512개\n",
        "model.fc = nn.Linear(num_ftrs, 10) # fc를 nn.Linear(num_ftrs, 10)로 대체, CIFAR10,,\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "ljlf-MYokPhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier 들어가기 직전에 값을 뽑아낼 것임\n",
        "# (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "print(model)"
      ],
      "metadata": {
        "id": "GnMOmvJkkSsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###T-SNE"
      ],
      "metadata": {
        "id": "V4SVucEQE6Us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 데이터 T-SNE"
      ],
      "metadata": {
        "id": "5TFLcCCID9u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual = []\n",
        "deep_features = []\n",
        "\n",
        "# Define a color map for each class\n",
        "color_map = plt.cm.get_cmap('tab10', len(malware_list))\n",
        "\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        features = model(images)\n",
        "\n",
        "        deep_features += features.cpu().numpy().tolist()\n",
        "        actual += labels.cpu().numpy().tolist()"
      ],
      "metadata": {
        "id": "dGneXg6ulBLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=55, metric='manhattan')\n",
        "cluster = np.array(tsne.fit_transform(np.array(deep_features)))\n",
        "actual = np.array(actual)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "def color_map(index):\n",
        "    # Define your color map logic here\n",
        "    colors = ['red', 'blue']  # Example color map\n",
        "    return colors[index]\n",
        "\n",
        "for label, malware_type in malware_list.items():\n",
        "    malware_type_arr = np.array([malware_type] * len(actual))  # Convert malware_type to a NumPy array\n",
        "    idx = np.where(actual == malware_type_arr)\n",
        "    plt.scatter(cluster[idx, 0], cluster[idx, 1], marker='.', label=label, color=color_map(malware_type))\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "w-rGnrc86IrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tsne = TSNE(n_components=3, perplexity=55, metric='manhattan')\n",
        "cluster = np.array(tsne.fit_transform(np.array(deep_features)))\n",
        "actual = np.array(actual)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "def color_map(index):\n",
        "    # Define your color map logic here\n",
        "    colors = ['red', 'blue']  # Example color map\n",
        "    return colors[index]\n",
        "\n",
        "for label, malware_type in malware_list.items():\n",
        "    malware_type_arr = np.array([malware_type] * len(actual))  # Convert malware_type to a NumPy array\n",
        "    idx = np.where(actual == malware_type_arr)\n",
        "    plt.scatter(cluster[idx, 0], cluster[idx, 1], marker='.', label=label, color=color_map(malware_type))\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hrMj2y9_aS8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test_data TSNE"
      ],
      "metadata": {
        "id": "0sM7AQyyxtdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual = []\n",
        "deep_features = []\n",
        "\n",
        "# Define a color map for each class\n",
        "color_map = plt.cm.get_cmap('tab10', len(malware_list))\n",
        "\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        features = model(images)\n",
        "\n",
        "        deep_features += features.cpu().numpy().tolist()\n",
        "        actual += labels.cpu().numpy().tolist()"
      ],
      "metadata": {
        "id": "tS9QNOFtxs5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=55, metric='manhattan')\n",
        "cluster = np.array(tsne.fit_transform(np.array(deep_features)))\n",
        "actual = np.array(actual)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "def color_map(index):\n",
        "    # Define your color map logic here\n",
        "    colors = ['red', 'blue']  # Example color map\n",
        "    return colors[index]\n",
        "\n",
        "for label, malware_type in malware_list.items():\n",
        "    malware_type_arr = np.array([malware_type] * len(actual))  # Convert malware_type to a NumPy array\n",
        "    idx = np.where(actual == malware_type_arr)\n",
        "    plt.scatter(cluster[idx, 0], cluster[idx, 1], marker='.', label=label, color=color_map(malware_type))\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_q2Jk1GtuwUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구성"
      ],
      "metadata": {
        "id": "XMOtVX1T8zu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "e0yB7kJWG9oC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learing result of HOG descriptor"
      ],
      "metadata": {
        "id": "8MyqI5dU_1LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "# Define scoring functions\n",
        "scores = {\n",
        "    'Accuracy': accuracy_score,\n",
        "    'Precision': precision_score,\n",
        "    'Recall': recall_score,\n",
        "    'F1': f1_score,\n",
        "    'Confusion Matrix': confusion_matrix\n",
        "}\n",
        "\n",
        "# Model definitions\n",
        "models = [\n",
        "    ('Random Forest', make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100))),\n",
        "    ('XGBoost', XGBClassifier(learning_rate=0.01, reg_lambda=0.1)),\n",
        "    ('Linear SVM', make_pipeline(StandardScaler(), LinearSVC(penalty='l2', dual=False))),\n",
        "    ('SMO', make_pipeline(StandardScaler(), SVC(kernel='rbf', C=1.0, gamma='scale', probability=True))),\n",
        "    ('J48', DecisionTreeClassifier())\n",
        "]\n",
        "# Define a function to plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, model_name):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "class_names = ['Malware', 'Benign']\n",
        "# Ensemble model definition\n",
        "ensemble_model = VotingClassifier(models, voting='hard')\n",
        "\n",
        "# Cross-validation and evaluation for each model\n",
        "for model_name, model_instance in models:\n",
        "    print(model_name)\n",
        "    model_instance.fit(X_train, train_labels)\n",
        "    y_pred = model_instance.predict(X_test)\n",
        "    for score_name, score_func in scores.items():\n",
        "        # if score_name == 'Confusion Matrix':\n",
        "        #     cm = score_func(test_label, y_pred)\n",
        "        #     print(score_name)\n",
        "        #     print(cm)\n",
        "        #     plot_confusion_matrix(cm, class_names, model_name)\n",
        "\n",
        "        # else:\n",
        "            print(score_name, score_func(test_label, y_pred))\n",
        "\n",
        "# Ensemble model training and evaluation\n",
        "ensemble_model.fit(X_train, train_labels)\n",
        "y_pred_ensemble = ensemble_model.predict(X_test)"
      ],
      "metadata": {
        "id": "j-mFk72f_yVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machin learning and model ensemble result of GIST"
      ],
      "metadata": {
        "id": "RRFRMJonAYjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "# Define scoring functions\n",
        "scores = {\n",
        "    'Accuracy': accuracy_score,\n",
        "    'Precision': precision_score,\n",
        "    'Recall': recall_score,\n",
        "    'F1': f1_score,\n",
        "    'Confusion Matrix': confusion_matrix\n",
        "}\n",
        "\n",
        "# Model definitions\n",
        "models = [\n",
        "    ('Random Forest', make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100))),\n",
        "    ('XGBoost', XGBClassifier(learning_rate=0.01, reg_lambda=0.1)),\n",
        "    ('Linear SVM', make_pipeline(StandardScaler(), LinearSVC(penalty='l2', dual=False))),\n",
        "    ('SMO', make_pipeline(StandardScaler(), SVC(kernel='rbf', C=1.0, gamma='scale', probability=True))),\n",
        "    ('J48', DecisionTreeClassifier())\n",
        "]\n",
        "# Define a function to plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, model_name):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "class_names = ['Malware', 'Benign']\n",
        "# Ensemble model definition\n",
        "ensemble_model = VotingClassifier(models, voting='hard')\n",
        "\n",
        "# Cross-validation and evaluation for each model\n",
        "for model_name, model_instance in models:\n",
        "    print(model_name)\n",
        "    model_instance.fit(X_train, train_labels)\n",
        "    y_pred = model_instance.predict(X_test)\n",
        "    for score_name, score_func in scores.items():\n",
        "        # if score_name == 'Confusion Matrix':\n",
        "        #     cm = score_func(test_label, y_pred)\n",
        "        #     print(score_name)\n",
        "        #     print(cm)\n",
        "        #     plot_confusion_matrix(cm, class_names, model_name)\n",
        "\n",
        "        # else:\n",
        "            print(score_name, score_func(test_label, y_pred))\n",
        "\n",
        "# Ensemble model training and evaluation\n",
        "ensemble_model.fit(X_train, train_labels)\n",
        "y_pred_ensemble = ensemble_model.predict(X_test)"
      ],
      "metadata": {
        "id": "SmteEYnvdI2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Define a function to plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, model_name):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "class_names = ['Malware', 'Benign']\n",
        "\n",
        "print('Ensemble Model')\n",
        "for score_name, score_func in scores.items():\n",
        "    if score_name == 'Confusion Matrix':\n",
        "        cm = score_func(test_label, y_pred_ensemble)\n",
        "        print(score_name)\n",
        "        print(cm)\n",
        "        plot_confusion_matrix(cm, class_names, 'Ensemble Model')\n",
        "    else:\n",
        "        print(score_name, score_func(test_label, y_pred_ensemble))"
      ],
      "metadata": {
        "id": "mqiMDLZunByT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = [\n",
        "    ('XGBoost', xgb.XGBClassifier()),\n",
        "    ('Linear SVM', LinearSVC()),\n",
        "    ('SMO', SVC(kernel='poly', coef0=1.0, C=1.0, degree=3)),\n",
        "    ('Random Forest', RandomForestClassifier(n_estimators=100)),\n",
        "    ('J48', DecisionTreeClassifier(max_depth=6))\n",
        "]\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    return rmse\n",
        "\n",
        "def run_cross_validation(X_train, train_labels, models, n_splits=5):\n",
        "    scores = {model_name: {'Validation Accuracy': [], 'Validation Loss': []} for model_name, _ in models}\n",
        "\n",
        "    cv = StratifiedKFold(n_splits = n_splits)\n",
        "    for train_index, val_index in cv.split(X_train, train_labels):\n",
        "        X_cv_train, X_cv_val = X_train[train_index], X_train[val_index]\n",
        "        train_labels = np.array(train_labels)  # 이 줄을 추가하여 train_labels를 numpy 배열로 변환합니다.\n",
        "        y_cv_train, y_cv_val = train_labels[train_index], train_labels[val_index]\n",
        "\n",
        "        for model_name, model_instance in models:\n",
        "            print(f\"Processing {model_name}...\")\n",
        "            sc = StandardScaler()\n",
        "            X_cv_train_std = sc.fit_transform(X_cv_train)\n",
        "            model = model_instance\n",
        "            model.fit(X_cv_train_std, y_cv_train)\n",
        "\n",
        "            X_cv_val_std = sc.transform(X_cv_val)\n",
        "            y_val_pred = model.predict(X_cv_val_std)\n",
        "            scores[model_name]['Validation Accuracy'].append(accuracy_score(y_cv_val, y_val_pred))\n",
        "            scores[model_name]['Validation Loss'].append(root_mean_squared_error(y_cv_val, y_val_pred))\n",
        "\n",
        "    return scores\n",
        "\n",
        "scores_per_model = run_cross_validation(X_train, train_labels, models)\n",
        "\n",
        "# Plot validation accuracy per model\n",
        "n_splits = 5  # or any positive integer value\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "for model_name, model_scores in scores_per_model.items():\n",
        "    plt.plot(range(1, n_splits + 1), model_scores['Validation Accuracy'], label=model_name)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot validation loss per model\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Loss')\n",
        "for model_name, model_scores in scores_per_model.items():\n",
        "    plt.plot(range(1, n_splits + 1), model_scores['Validation Loss'], label=model_name)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ZM-8u9UAgyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machin Learning result abd model ensemble of SIFT"
      ],
      "metadata": {
        "id": "9nmxrc8vAzRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "# Define scoring functions\n",
        "scores = {\n",
        "    'Accuracy': accuracy_score,\n",
        "    'Precision': precision_score,\n",
        "    'Recall': recall_score,\n",
        "    'F1': f1_score,\n",
        "    'Confusion Matrix': confusion_matrix\n",
        "}\n",
        "\n",
        "# Model definitions\n",
        "models = [\n",
        "    ('Random Forest', make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100))),\n",
        "    ('XGBoost', XGBClassifier(learning_rate=0.01, reg_lambda=0.1)),\n",
        "    ('Linear SVM', make_pipeline(StandardScaler(), LinearSVC(penalty='l2', dual=False))),\n",
        "    ('SMO', make_pipeline(StandardScaler(), SVC(kernel='rbf', C=1.0, gamma='scale', probability=True))),\n",
        "    ('J48', DecisionTreeClassifier())\n",
        "]\n",
        "# Define a function to plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, model_name):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "class_names = ['Malware', 'Benign']\n",
        "# Ensemble model definition\n",
        "ensemble_model = VotingClassifier(models, voting='hard')\n",
        "\n",
        "# Cross-validation and evaluation for each model\n",
        "for model_name, model_instance in models:\n",
        "    print(model_name)\n",
        "    model_instance.fit(X_train, train_labels)\n",
        "    y_pred = model_instance.predict(X_test)\n",
        "    for score_name, score_func in scores.items():\n",
        "        # if score_name == 'Confusion Matrix':\n",
        "        #     cm = score_func(test_label, y_pred)\n",
        "        #     print(score_name)\n",
        "        #     print(cm)\n",
        "        #     plot_confusion_matrix(cm, class_names, model_name)\n",
        "\n",
        "        # else:\n",
        "            print(score_name, score_func(test_label, y_pred))\n",
        "\n",
        "# Ensemble model training and evaluation\n",
        "ensemble_model.fit(X_train, train_labels)\n",
        "y_pred_ensemble = ensemble_model.predict(X_test)"
      ],
      "metadata": {
        "id": "byw0Pm-PZZCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ensemble model result"
      ],
      "metadata": {
        "id": "h0iW3jNy_933"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Ensemble Model')\n",
        "for score_name, score_func in scores.items():\n",
        "    if score_name == 'Confusion Matrix':\n",
        "        cm = score_func(test_label, y_pred_ensemble)\n",
        "        print(score_name)\n",
        "        print(cm)\n",
        "        plot_confusion_matrix(cm, class_names, 'Ensemble Model')\n",
        "\n",
        "    else:\n",
        "        print(score_name, score_func(test_label, y_pred_ensemble))"
      ],
      "metadata": {
        "id": "KTgqHFhSgdLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Define a function to plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, model_name):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "class_names = ['Malware', 'Benign']\n",
        "\n",
        "print('Ensemble Model')\n",
        "for score_name, score_func in scores.items():\n",
        "    if score_name == 'Confusion Matrix':\n",
        "        cm = score_func(test_label, y_pred_ensemble)\n",
        "        print(score_name)\n",
        "        print(cm)\n",
        "        plot_confusion_matrix(cm, class_names, 'Ensemble Model')\n",
        "    else:\n",
        "        print(score_name, score_func(test_label, y_pred_ensemble))"
      ],
      "metadata": {
        "id": "gC_5KxqEZRWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation acurracy, loss"
      ],
      "metadata": {
        "id": "ZFNz1neEAEKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = [\n",
        "    ('XGBoost', xgb.XGBClassifier()),\n",
        "    ('Linear SVM', LinearSVC()),\n",
        "    ('SMO', SVC(kernel='poly', coef0=1.0, C=1.0, degree=3)),\n",
        "    ('Random Forest', RandomForestClassifier(n_estimators=100)),\n",
        "    ('J48', DecisionTreeClassifier(max_depth=6))\n",
        "]\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    return rmse\n",
        "\n",
        "def run_cross_validation(X_train, train_labels, models, n_splits=5):\n",
        "    scores = {model_name: {'Validation Accuracy': [], 'Validation Loss': []} for model_name, _ in models}\n",
        "\n",
        "    cv = StratifiedKFold(n_splits = n_splits)\n",
        "    for train_index, val_index in cv.split(X_train, train_labels):\n",
        "        X_cv_train, X_cv_val = X_train[train_index], X_train[val_index]\n",
        "        y_cv_train, y_cv_val = train_labels[train_index], train_labels[val_index]\n",
        "\n",
        "        for model_name, model_instance in models:\n",
        "            print(f\"Processing {model_name}...\")\n",
        "            sc = StandardScaler()\n",
        "            X_cv_train_std = sc.fit_transform(X_cv_train)\n",
        "            model = model_instance\n",
        "            model.fit(X_cv_train_std, y_cv_train)\n",
        "\n",
        "            X_cv_val_std = sc.transform(X_cv_val)\n",
        "            y_val_pred = model.predict(X_cv_val_std)\n",
        "            scores[model_name]['Validation Accuracy'].append(accuracy_score(y_cv_val, y_val_pred))\n",
        "            scores[model_name]['Validation Loss'].append(root_mean_squared_error(y_cv_val, y_val_pred))\n",
        "\n",
        "    return scores\n",
        "\n",
        "scores_per_model = run_cross_validation(X_train, train_labels, models)\n",
        "\n",
        "# Plot validation accuracy per model\n",
        "n_splits = 5  # or any positive integer value\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "for model_name, model_scores in scores_per_model.items():\n",
        "    plt.plot(range(1, n_splits + 1), model_scores['Validation Accuracy'], label=model_name)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot validation loss per model\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Loss')\n",
        "for model_name, model_scores in scores_per_model.items():\n",
        "    plt.plot(range(1, n_splits + 1), model_scores['Validation Loss'], label=model_name)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HaAZSCCuAEo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning"
      ],
      "metadata": {
        "id": "xBZt7eFTG_eR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model List"
      ],
      "metadata": {
        "id": "JLjcF_rC_l-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model-DNN basic"
      ],
      "metadata": {
        "id": "J9vUxXejz2yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DNN 모델 클래스 정의\n",
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(224 * 224 * 3, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 2)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # 입력 이미지를 1차원\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = DNN().to(device)"
      ],
      "metadata": {
        "id": "UNJAZzLDz-04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model-CNN basic"
      ],
      "metadata": {
        "id": "wUdQojxBz84J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, 3) # in_channel, out_channel, kernel size\n",
        "        self.pool = nn.MaxPool2d(3, 2) # kernel_size, stride\n",
        "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
        "        self.fc1 = nn.Linear(56180, 160) # in_features, out_features\n",
        "        self.fc2 = nn.Linear(160, 120)\n",
        "        self.fc3 = nn.Linear(120, 2)\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "pERX_s800Aj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model-ResNet50"
      ],
      "metadata": {
        "id": "DmnCSZA68p1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Refined_ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super(Refined_ResNet, self).__init__()\n",
        "\n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "\n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "\n",
        "        self.layer1 = self.get_model_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_model_layer(block, n_blocks[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_model_layer(block, n_blocks[2], channels[2], stride = 2)\n",
        "        self.layer4 = self.get_model_layer(block, n_blocks[3], channels[3], stride = 2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "\n",
        "    def get_model_layer(self, block, n_blocks, channels, stride = 1):\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "\n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "\n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "3GIVUYCI8ZHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3,\n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,\n",
        "                               stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1,\n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        i = x\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "QRb75CaC8YpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1,\n",
        "                               stride = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,\n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
        "                               stride = 1, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1,\n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        i = x\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "twSUre1m8YYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model_info"
      ],
      "metadata": {
        "id": "7tQhxT6P8viD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "Model_Info = namedtuple('Model_Info', ['block', 'n_blocks', 'channels'])\n",
        "\n",
        "Model_config = Model_Info(block = Bottleneck,\n",
        "                               n_blocks = [3, 4, 6, 3],\n",
        "                               channels = [64, 128, 256, 512])"
      ],
      "metadata": {
        "id": "3SDkZ6Nb8xO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "pretrained_model = models.resnet50(pretrained = True)\n",
        "\n",
        "# Fine Tuning\n",
        "IN_FEATURES = pretrained_model.fc.in_features\n",
        "OUTPUT_DIM = 2\n",
        "\n",
        "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
        "pretrained_model.fc = fc"
      ],
      "metadata": {
        "id": "4emuVAQs8ylG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Refined_ResNet(Model_config, OUTPUT_DIM).to(device)"
      ],
      "metadata": {
        "id": "-UUZtyC10ahL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Load\n",
        "model.load_state_dict(pretrained_model.state_dict())"
      ],
      "metadata": {
        "id": "cseDfD2K8zfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "id": "-25g1f6h80Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR_finder"
      ],
      "metadata": {
        "id": "5WjFwY-a80lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "3BD5cyC182aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Summary\n",
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "output = model(x)\n",
        "\n",
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "id": "iTxkpY_A83OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LRFinder:\n",
        "    def __init__(self, model, optimizer, criterion, device):\n",
        "\n",
        "        self.optimizer = optimizer\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "\n",
        "        torch.save(model.state_dict(), 'init_params.pt')\n",
        "\n",
        "    def range_test(self, iterator, end_lr = 10, num_iter = 100,\n",
        "                   smooth_f = 0.05, diverge_th = 5):\n",
        "\n",
        "        lrs = []\n",
        "        losses = []\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
        "\n",
        "        iterator = IteratorWrapper(iterator)\n",
        "\n",
        "        for iteration in range(num_iter):\n",
        "\n",
        "            loss = self._train_batch(iterator)\n",
        "\n",
        "            #update lr\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            lrs.append(lr_scheduler.get_lr()[0])\n",
        "\n",
        "            if iteration > 0:\n",
        "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
        "\n",
        "            if loss < best_loss:\n",
        "                best_loss = loss\n",
        "\n",
        "            losses.append(loss)\n",
        "\n",
        "            if loss > diverge_th * best_loss:\n",
        "                print(\"Stopping early, the loss has diverged\")\n",
        "                break\n",
        "\n",
        "        #reset model to initial parameters\n",
        "        model.load_state_dict(torch.load('init_params.pt'))\n",
        "\n",
        "        return lrs, losses\n",
        "\n",
        "    def _train_batch(self, iterator):\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        x, y = iterator.get_batch()\n",
        "\n",
        "        x = x.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "\n",
        "        y_pred = self.model(x)\n",
        "\n",
        "        loss = self.criterion(y_pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "class ExponentialLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        curr_iter = self.last_epoch + 1\n",
        "        r = curr_iter / self.num_iter\n",
        "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
        "\n",
        "class IteratorWrapper:\n",
        "    def __init__(self, iterator):\n",
        "        self.iterator = iterator\n",
        "        self._iterator = iter(iterator)\n",
        "\n",
        "    def __next__(self):\n",
        "        try:\n",
        "            inputs, labels, _, _ = next(self._iterator)\n",
        "        except StopIteration:\n",
        "            self._iterator = iter(self.iterator)\n",
        "            inputs, labels, _, _ = next(self._iterator)\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def get_batch(self):\n",
        "        return next(self)"
      ],
      "metadata": {
        "id": "zVpRNNGX848A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "metadata": {
        "id": "gsyb7oK885n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 30):\n",
        "\n",
        "    if skip_end == 0:\n",
        "        lrs = lrs[skip_start:]\n",
        "        losses = losses[skip_start:]\n",
        "    else:\n",
        "        lrs = lrs[skip_start:-skip_end]\n",
        "        losses = losses[skip_start:-skip_end]\n",
        "\n",
        "    fig = plt.figure(figsize = (16,8))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.plot(lrs, losses)\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_xlabel('Learning rate')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.grid(True, 'both', 'x')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aGmKF75Q878P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOUND_LR = 1e-4\n",
        "\n",
        "params = [\n",
        "          {'params': model.conv1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.bn1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.layer1.parameters(), 'lr': FOUND_LR / 8},\n",
        "          {'params': model.layer2.parameters(), 'lr': FOUND_LR / 6},\n",
        "          {'params': model.layer3.parameters(), 'lr': FOUND_LR / 4},\n",
        "          {'params': model.layer4.parameters(), 'lr': FOUND_LR / 2},\n",
        "          {'params': model.fc.parameters()}\n",
        "         ]\n",
        "\n",
        "optimizer = optim.Adam(params, lr = FOUND_LR)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)"
      ],
      "metadata": {
        "id": "2oUFzEwX88sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='.init_params.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: '.init_params.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "TQauBjM58957"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "LmhpfKR387Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for (x, y, _, _) in iterator:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(x)\n",
        "\n",
        "        loss = criterion(y_pred, y)\n",
        "        acc = (y_pred.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc /= len(iterator)\n",
        "\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "qO-WJvKE9Aqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y, _, _) in iterator:\n",
        "\n",
        "           x = x.to(device)\n",
        "           y = y.to(device)\n",
        "\n",
        "           y_pred = model(x)\n",
        "\n",
        "           loss = criterion(y_pred, y)\n",
        "           acc = (y_pred.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "           epoch_loss += loss.item()\n",
        "           epoch_acc += acc.item()\n",
        "\n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc /= len(iterator)\n",
        "\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "yfFjUgwB9Cjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "k6XPUIJz9DSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "result_list = []\n",
        "lr_list = []\n",
        "\n",
        "patience = 5\n",
        "\n",
        "early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
        "\n",
        "for epoch in range(100):\n",
        "\n",
        "    start_time = time.monotonic()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_loader, criterion, device)\n",
        "\n",
        "    early_stopping(valid_loss, model)\n",
        "    lr_list.append(optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "    # patience 동안 val_loss가 감소하지 않으면 조기 종료\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break\n",
        "\n",
        "    # val_loss 감소하면 best model 불러오기\n",
        "    model.load_state_dict(torch.load('./init_params.pt'))\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:6.2f}%')\n",
        "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:6.2f}%')\n",
        "\n",
        "    result = {\n",
        "    'EPOCH': epoch,\n",
        "    'Train Loss': train_loss,\n",
        "    'Train acc': train_acc,\n",
        "    'Valid Loss': valid_loss,\n",
        "    'Valid acc': valid_acc}\n",
        "\n",
        "    result_list.append(result)"
      ],
      "metadata": {
        "id": "5ydfXopX9D3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가"
      ],
      "metadata": {
        "id": "18G7yplz89Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.DataFrame(result_list)"
      ],
      "metadata": {
        "id": "aBbf_Hzh06bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss 및 Acc 변화 그래프\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "axes[0].plot(result_df['EPOCH'], result_df['Train Loss'], label='Train Loss')\n",
        "axes[0].plot(result_df['EPOCH'], result_df['Valid Loss'], label='Valid Loss')\n",
        "axes[0].legend()\n",
        "axes[0].set_title('Loss')\n",
        "\n",
        "axes[1].plot(result_df['EPOCH'], result_df['Train acc'], label='Train acc')\n",
        "axes[1].plot(result_df['EPOCH'], result_df['Valid acc'], label='Valid acc')\n",
        "axes[1].legend()\n",
        "axes[1].set_title('ACC')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IhKgwzon9zG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lr_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Learning Rate\")"
      ],
      "metadata": {
        "id": "5JihiaQO-2Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('.init_params.pt'))"
      ],
      "metadata": {
        "id": "cBcW3D2388_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=False)"
      ],
      "metadata": {
        "id": "z5elxAx_1AdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc @1: {test_acc*100:6.2f}%')"
      ],
      "metadata": {
        "id": "Sm2k60Cc1BD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 항목별 정확도 및 컨퓨전 매트릭스\n",
        "nb_classes = 2\n",
        "\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "with torch.no_grad():\n",
        "    for idx, (inputs, classes, _, _) in enumerate(test_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "\n",
        "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
      ],
      "metadata": {
        "id": "x6X7sGdF1Cxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컨퓨전 매트릭스 heatmap 그리기\n",
        "\n",
        "binary_list = ['Malware', 'Benign']\n",
        "plt.figure(figsize=(6, 6))\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix');\n",
        "ax.xaxis.set_ticklabels(binary_list); ax.yaxis.set_ticklabels(binary_list);"
      ],
      "metadata": {
        "id": "AP1r4mIL1EiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual = []\n",
        "deep_features = []\n",
        "\n",
        "# Define a color map for each class\n",
        "color_map = plt.cm.get_cmap('tab10', len(binary_list))\n",
        "\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        features = model(images)\n",
        "\n",
        "        deep_features += features.cpu().numpy().tolist()\n",
        "        actual += labels.cpu().numpy().tolist()"
      ],
      "metadata": {
        "id": "FxudDSpj1HBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "malware_list = {'Malware' : 1, 'Benign' : 0}\n",
        "\n",
        "tsne = TSNE(n_components=2, metric='manhattan')\n",
        "cluster = np.array(tsne.fit_transform(np.array(deep_features)))\n",
        "actual = np.array(actual)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "\n",
        "for label, malware_type in malware_list.items():\n",
        "    malware_type_arr = np.array([malware_type] * len(actual))  # Convert malware_type to a NumPy array\n",
        "    idx = np.where(actual == malware_type_arr)\n",
        "    plt.scatter(cluster[idx, 0], cluster[idx, 1], marker='.', label=label)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fcqkT13t1IU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 결과 분석 - Heatmap"
      ],
      "metadata": {
        "id": "hszkcCEE1UR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# 이미지를 히트맵으로 시각화하는 함수\n",
        "def visualize_heatmap(image_path, model, target_layer, ax):\n",
        "    # 이미지 불러오기\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # 이미지 전처리\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    input_tensor = preprocess(image)\n",
        "    input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "    # 입력 텐서와 모델의 가중치를 동일한 디바이스에 위치시키기\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    input_batch = input_batch.to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    # 모델의 특징 맵 추출하기\n",
        "    model.eval()\n",
        "    features = []\n",
        "    def hook_fn(module, input, output):\n",
        "        features.append(output.data.cpu().numpy())\n",
        "    hook = target_layer.register_forward_hook(hook_fn)\n",
        "    with torch.no_grad():\n",
        "        _ = model(input_batch)\n",
        "    hook.remove()\n",
        "\n",
        "    # 히트맵 생성하기\n",
        "    heatmap = torch.mean(torch.tensor(features[0]), dim=1).squeeze()\n",
        "    heatmap = nn.functional.relu(heatmap)\n",
        "    heatmap /= torch.max(heatmap)\n",
        "\n",
        "    # 히트맵을 원본 이미지에 적용하기\n",
        "    heatmap = heatmap.detach().cpu().numpy()\n",
        "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # 원본 이미지와 히트맵을 겹쳐서 시각화하기\n",
        "    superimposed_img = cv2.addWeighted(image, 0.5, heatmap, 0.5, 0)\n",
        "\n",
        "    # 이미지 출력\n",
        "    ax.imshow(superimposed_img)\n",
        "    ax.axis('off')\n",
        "\n",
        "target_layer = model.layer4[-1]\n"
      ],
      "metadata": {
        "id": "cKlXGDR31XZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misclassified_images = []\n",
        "misclassified_labels = []\n",
        "misclassified_indices = []\n",
        "misclassified_file_paths = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels, file_paths, _ in test_loader:  # 테스트 로더에서 파일 경로를 제공하는 것으로 가정합니다\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        misclassified_idx = (predicted != labels).nonzero()\n",
        "\n",
        "        misclassified_images.extend(images[misclassified_idx])\n",
        "        misclassified_labels.extend(predicted[misclassified_idx])\n",
        "        misclassified_indices.extend(misclassified_idx)\n",
        "\n",
        "        for idx in range(len(misclassified_idx.view(-1))):\n",
        "          misclassified_file_paths.append(file_paths[misclassified_idx.view(-1)[idx]])\n",
        "\n"
      ],
      "metadata": {
        "id": "VKYUhzo01Y5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary = {0 : 'Benign', 1 : 'Malware'}"
      ],
      "metadata": {
        "id": "jk12uIEi1ach"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_string_between(path):\n",
        "    pattern = r'Test/(.*?)/'\n",
        "    match = re.search(pattern, path)\n",
        "    if match:\n",
        "        extracted_string = match.group(1)\n",
        "        return extracted_string\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "m5XkQeoZ1coG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잘못 예측한 데이터 개수 확인\n",
        "misclassified_count = len(misclassified_images)\n",
        "\n",
        "# 잘못 예측한 데이터 시각화 및 히트맵 생성\n",
        "num_images = min(9, misclassified_count)\n",
        "fig, axes = plt.subplots(int(num_images/3), 3, figsize=(8, 6))\n",
        "\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    if i < misclassified_count:\n",
        "        image = misclassified_images[i].cpu().numpy()\n",
        "        file_path = misclassified_file_paths[i]\n",
        "\n",
        "        # 이미지 차원 순서 확인 및 수정\n",
        "        if image.shape[0] == 1:  # 흑백 이미지인 경우\n",
        "            image = np.squeeze(image, axis=0)  # 채널 차원 제거\n",
        "        else:  # 컬러 이미지인 경우\n",
        "            image = image.transpose((1, 2, 0))\n",
        "\n",
        "        label = misclassified_labels[i].item()\n",
        "        index = misclassified_indices[i].item()\n",
        "\n",
        "        image = np.transpose(image, (1, 2, 0))\n",
        "\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(f\"Predict: {'Benign' if label == 0 else 'Malware'}\\nTrue: {extract_string_between(file_path)}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qv1Dua7K1ds-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잘못 예측한 데이터 개수 확인\n",
        "misclassified_count = len(misclassified_images)\n",
        "\n",
        "# 잘못 예측한 데이터 시각화 및 히트맵 생성\n",
        "num_images = min(9, misclassified_count)\n",
        "fig, axes = plt.subplots(int(num_images/3), 3, figsize=(12, 6))\n",
        "\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    if i < misclassified_count:\n",
        "        file_path = misclassified_file_paths[i]\n",
        "\n",
        "        ax.imshow(plt.imread(file_path))\n",
        "        ax.set_title(f\"Predict: {'Benign' if label == 0 else 'Malware'}\\nTrue: {extract_string_between(file_path)}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "        # 히트맵 생성\n",
        "        visualize_heatmap(file_path, model, target_layer, ax)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R9lWyygp1fBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = min(9, misclassified_count)\n",
        "fig, axes = plt.subplots(int(num_images/3), 3, figsize=(8, 6))\n",
        "\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    if i < misclassified_count:\n",
        "        file_path = misclassified_file_paths[i]\n",
        "\n",
        "        # 이미지 불러오기 및 전처리\n",
        "        image = Image.open(file_path).convert('RGB')\n",
        "        preprocess = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        input_tensor = preprocess(image)\n",
        "        input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "        # 입력 텐서와 모델의 가중치를 동일한 디바이스에 위치시키기\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        input_batch = input_batch.to(device)\n",
        "        model.to(device)\n",
        "\n",
        "        # 모델의 특징 맵 추출하기\n",
        "        model.eval()\n",
        "        features = []\n",
        "        def hook_fn(module, input, output):\n",
        "            features.append(output.data.cpu().numpy())\n",
        "        hook = target_layer.register_forward_hook(hook_fn)\n",
        "        with torch.no_grad():\n",
        "            _ = model(input_batch)\n",
        "        hook.remove()\n",
        "\n",
        "        # 히트맵 생성하기\n",
        "        heatmap = torch.mean(torch.tensor(features[0]), dim=1).squeeze()\n",
        "        heatmap = nn.functional.relu(heatmap)\n",
        "        heatmap /= torch.max(heatmap)\n",
        "\n",
        "        # 원본 이미지와 히트맵을 겹쳐서 시각화하기\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(f\"Predict: {'Benign' if label == 0 else 'Malware'}\\nTrue: {extract_string_between(file_path)}\")\n",
        "        ax.imshow(heatmap, alpha=0.6, cmap='jet')\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nu1VV7Qd1hNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Move the model to the desired device (CPU or CUDA)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Modify the linear layer to have a single output neuron\n",
        "model.fc = nn.Linear(2048, 2)\n",
        "\n",
        "# Create empty dictionaries to store class features and counts\n",
        "class_features = {0: [], 1: []}\n",
        "class_counts = {0: 0, 1: 0}\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Iterate over the train_loader to extract class features\n",
        "with torch.no_grad():\n",
        "    for images, labels, _, _ in train_loader:\n",
        "        # Move images and labels to the device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass through the model\n",
        "        features = model(images)\n",
        "\n",
        "        # Update class features and counts\n",
        "        for feature, label in zip(features, labels):\n",
        "            class_features[label.item()].append(feature)\n",
        "            class_counts[label.item()] += 1\n",
        "\n",
        "# Calculate average features for each class\n",
        "class_avg_features = {}\n",
        "for label, features in class_features.items():\n",
        "    avg_features = torch.stack(features).mean(dim=0)\n",
        "    class_avg_features[label] = avg_features\n",
        "\n",
        "# Normalize and visualize the heatmaps\n",
        "for label, avg_features in class_avg_features.items():\n",
        "    heatmap = nn.functional.relu(avg_features)\n",
        "    heatmap /= torch.max(heatmap)\n",
        "\n",
        "    # Visualize the heatmap\n",
        "    plt.imshow(heatmap.squeeze().cpu(), cmap='jet')\n",
        "    plt.title(f'Class {label} Heatmap')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ZRydJmL91i44"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}